
asyncio task list:
1) CreateZip
2) data_na
3) duplicate_vector_check
4) extract_re_data
5) good_data
6) njr10k
7) update_njr10k

Tasks in njr10k: (Completed)
- request Session
- parse city and weburl info (turn this into its own function) task1
- inputs needed:
 - base_url
 - city
 - city_list
 - year
 - month
 - params
- download pdf
***make sure all tasks are put into the task list (NOT COMPLETE)

Tasks in data_na (COMPLETED)
- assign values to all of the variables
- input values into main dictionary
- put values into full year dictionary if necessary

Tasks in duplicate_vector_check (COMPLETED)
#May not even be a necessary function anymore
- get length of cities in dictionary

Tasks in extract_re_data
- parse pdf name
- check if pdf in corrupted list
- extract pdf contents
- if pdf is good, run good_data (task1)
    - good_data will run duplicate_vector_check (task3)
- if corrupt, run data_na (task2)

***make sure all tasks are put into the task list (NOT COMPLETE)


55) Function that sends the data to an SQL Database
69) Add a except KeyboardInterupt and sys.exit() for this exception
72) ***Look into aiohttp for async http requesting
- asyncio is pretty difficult to use
- there's something about the async setup that mixing up the split function for the cities with duplicate names
- the download pdf function isnt downloading anything
73) asynio Exceptions to my try-except blocks which use the module
74) Ensure the check_results module is running as it should (may not be useful anymore)
75) Change the os.walk(base_path) to os.listdir(base_path) in read_logger
There current code causes errors because its walking through all files and folders and trying to extract whats not there
https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory
76) Fix the outer code that checks the time to run the main program
    - Outer code will be turned in to a decorator
77) Should the event_log be saved after each event_log_update in the function or keep inside main()?
78) Edit the print of the event log created at the end of the update_10k and njr10k to have each item on new lines
    - Currently all being printed on one line
79) Change the message body of the text_message function so it returns all recent data (COMPLETED)
    - Currently returning the results of the first run
    - Text message looks good. Just fix up the way message looks
    (Check back in a few days to determine campaign registration status on Twilio.com or email)
80) Create decorator functions for these tasks:
    ***Use functool.wrapper to keep the metadata
 - Logger decorator function for:
    ***Change the logger level depending on the function running if possible
    - Corrupted_files (COMPLETED)
    - CreateZip (properly place logger messages in function)
    - extract_re_data (COMPLETED)
    - njr10k (COMPLETED)
    - njrdata (COMPLETED)
    - pandas2excel (COMPLETED)
    - update_njr10k (COMPLETED)
    - main (properly place logger messages in function)

87) Next_date may need to be a decorator function that runs obj.main()
88) Check the duplicate vector function to see if its needed and works as intended

89) Make sure all the column datatypes are correct

89) Make sure CreateZip runs as intended and the os.walk goes through all directories then set logger messages

45) If the program is killed due to an exception, I want to be able to rerun the program X number of times
81) Set the indexes in the df for pandas2excel to the cities (COMPLETED)
82) Fortify the df vectors with the corresponding dates of the data (COMPLETED)
        df = pd.DataFrame(dict1[k])
        df.assign(Dates = df['Month'] + '-' + df['Year'])
        df['Dates'] = pd.to_datetime(df['Dates'])
        df.to_excel(writer, sheet_name= k + ' By Qtr', index_col = 'City')
83) For pandas2exel: (COMPLETED)
    - join all the dfs in list1 and name the sheet "All Qtrs"
        all_qtrs = pd.concat(list1)
        all_qtrs.to_excel(writer, sheet_name = 'All Qtrs', index_col = 'City')
    - join all the dfs in list2 and name the sheet "All Years"
        all_years = pd.concat(list2)
        all_years.to_excel(writer, sheet_name = 'All Years', index_col = 'City')

86) Create a function to upload the GIS Data and create cloropleth maps and timeseries maps:
    def cloropleth_maps():
        import geopandas
        import plotly.express as px

        new_jersey = geopandas.read_file(filename, index = 'MUN')
        new_jersey.rename(columns = {'MUN': 'City'}, inplace = True)
        new_jersey[[column for column in new_jersey.columns]].sort_values(by=['City'])
        ***I have to sort the dfs by Qtr and year before plotting

        quarters = ['Q1', 'Q2', 'Q3', 'Q4']
        for sheet in list_of_excel_workbook_sheets:
            df = pd.read_excel('NJ 10k Real Estate', sheet)
            ***Create different dfs which are sorted dfs for Q1-Q4
            df_list = [df[[ for q in quarters
            fig = px.cloropleth(


85) Clean the joined dfs and use matplotlib to create line and histogram charts for each county:
*** This should be a function
    - Median Sales Price
    - New Listings
    - Closed Sales
    - Days on Market
    - PoLPR: line
    - Inventory of Homes for Sales
    - Months of Supply
    - Months of Supply
    *** Create a time-series graph on the map of New Jersey for these categories as well
    - Download the CSV or GeoJSON (using Geopandas) from https://gisdata-njdep.opendata.arcgis.com/datasets/newjersey::municipal-boundaries-of-nj/explore?location=40.084926%2C-74.743150%2C8.00&showTable=true
    - Make sure the GeoJSON index matches the df index (rename the 'MUN' column to 'City') and join/merge the dfs







Test String:
Key Metrics 2022 2023 Percent Change Thru 4-2022 Thru 4-2023 Percent Change
New Listings 25 13 - 48.0% 85 64 - 24.7%
Closed Sales 11 9 - 18.2% 46 37 - 19.6%
Days on Market Until Sale 36 42 + 16.7% 32 37 + 15.6%
Median Sales Price* $90,000 $101,000 + 12.2% $116,250 $95,000 - 18.3%
Percent of List Price Received* 107.8% 94.6% - 12.2% 99.7% 93.6% - 6.1%
Inventory of Homes for Sale 59 25 - 57.6% -- -- --
Months Supply of Inventory 4.8 2.0 - 58.3% -- -- --
Key Metrics 2022 2023 Percent Change Thru 4-2022 Thru 4-2023 Percent Change
New Listings 39 32 - 17.9% 134 131 - 2.2%
Closed Sales 19 34 + 78.9% 75 100 + 33.3%
Days on Market Until Sale 26 30 + 15.4% 39 46 + 17.9%
Median Sales Price* $70,000 $92,000 + 31.4% $72,334 $95,000 + 31.3%
Percent of List Price Received* 102.3% 99.8% - 2.4% 98.5% 97.6% - 0.9%
Inventory of Homes for Sale 86 61 - 29.1% -- -- --
Months Supply of Inventory 3.7 2.2 - 40.5% -- -- --
Key Metrics 2022 2023 Percent Change Thru 4-2022 Thru 4-2023 Percent Change
New Listings 0 0 -- 0 0 --
Closed Sales 0 0 -- 0 0 --
Days on Market Until Sale 0 0 -- 0 0 --
Median Sales Price* $0 $0 -- $0 $0 --
Percent of List Price Received* 0.0% 0.0% -- 0.0% 0.0% --
Inventory of Homes for Sale 0 0 -- -- -- --
Months Supply of Inventory 0.0 0.0 -- -- -- --
* Does not account for sale concessions and/or downpayment assistance.  |  Percent changes are calculated using rounded figures and can sometimes look extreme due to small sample size.Year to DateTownhouse-Condo April
Adult Community AprilYear to Date
Current as of May 20, 2023. All data from the multiple listing services in the state of New Jersey. Margin of error for reported statewide numbers is +/– 4% at a 95% confidence level. Report © 2023 ShowingTime.Local Market Update for April 2023
Provided by New Jersey REALTORS®
Camden City
Camden County
April Year to Date Single Family
$0$25,000$50,000$75,000$100,000$125,000$150,000$175,000
1-2010 1-2011 1-2012 1-2013 1-2014 1-2015 1-2016 1-2017 1-2018 1-2019 1-2020 1-2021 1-2022 1-2023Historical Median Sales Price by Property Type By Month
Single Family Townhouse-Condo Adult Community




8-4-23 Most recent updates (put in main file at home):
1) Put this in the for-loop in the main program to print better tables of the data

print(tabulate(main_dictionary['2022'], headers = 'keys', tablefmt = 'plain'))
print()
print(tabulate(main_dictionary['2023'], headers = 'keys', tablefmt = 'plain'))


4) New OrganizeFiles class (make sure to seperate .pdf and the logger files)



     | Traceback (most recent call last):
    |   File "F:/Python 2.0/Projects/Real Life Projects/NJRScrapper 8-17-23A.py", line 428, in download_pdf
    |     del city_list[city_list.index('/')]
    |                   ^^^^^^^^^^^^^^^^^^^^
    | ValueError: '/' is not in list

     | Traceback (most recent call last):
    |   File "F:/Python 2.0/Projects/Real Life Projects/NJRScrapper 8-17-23A.py", line 429, in download_pdf
    |     city_list.pop(city_list.index('/'))
    |                   ^^^^^^^^^^^^^^^^^^^^
    | ValueError: '/' is not in list

Traceback (most recent call last):
    |   File "F:/Python 2.0/Projects/Real Life Projects/NJRScrapper 8-17-23A.py", line 432, in download_pdf
    |     async with session_object.get(url3, params=params, stream=True) as reader, open(new_filename, 'wb') as writer:
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "F:\Python 2.0\pythonProject\venv\NJR Scrapper\Lib\site-packages\aiohttp\client.py", line 922, in get
    |     self._request(hdrs.METH_GET, url, allow_redirects=allow_redirects, **kwargs)
    | TypeError: ClientSession._request() got an unexpected keyword argument 'stream'

