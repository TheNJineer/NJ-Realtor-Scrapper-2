PRIORITY:

112) Refactor matplot_lines(filename, **kwargs) to create a figure for each city and will house
 the axes for the 5 categories from 2019. Will no longer track current year
113) Create a matplotlib chart formatter function to make main function less cluttered
106) Create an nj10k function which can take the city, county and **kwargs for args and download/extract pdfs
    - Create function which updates main_dictionary and full_year for missing data
    - Needed for when I need to download pdfs for one city or cities in particular
    - city arg can be a str or list object. Change code based on what the type is

******NJScrapper isn't currently getting data for Union Twp, NJ (Union County) or Union Twp, NJ (Hunterdon County)
108) Update extract_re_data to account for cities with the same name (DONE)
    - Cities with the same name but located in different counties arent getting extracted (DONE)
    because their format doesnt meet any of the logic in the program and doesnt raise any exceptions (DONE)
        - need to add an if statement for cities with '/' or 'County' in town ----> do this, else... (DONE)
109) Add doc-strings to all the methods of the class
95) Format the correct figures and axs  and figure sizes for matplot_lines()
- Configuring the figures to properly house all the axis (DONE)
- Setting the axis' and labels (DONE)
- Coloring the legends on each graph (DONE)
92) Create a method call quarterly_stats that runs the matplot_lines and njr10k_stats/njr10k_update_stats,
    cloropleth, histograms and Seaborn
86) Create a function to upload the GIS Data and create cloropleth maps and timeseries maps:
102) Dynamically changing the bbox_to_anchor coordinates to stay in the same place in the figure
I think its based on the amount of cities in the legend box. Play wit this (DONE)
    - Figure out which corner of the legend is this based off of and go from there (DONE)
111) Auto save the figures to the respective folder without opening them
    - Figure out how to name the file and fit all charts onto one page (DONE)
103) Fix the Y-axis for the 'Median Sales Price' graph (NOT NECESSSARY)
105) Handle this warning:
F:/Python 2.0/Projects/Real Life Projects/OG NJRScrapper Non-Ascynio 10-4-23.py:1119: UserWarning: Boolean Series key will be reindexed to match DataFrame index.
  target1_df = temp1_df1[temp_df1['City'] == city]

_________________________________________________________________________________________________________________________________________


110) Clean all the strong and weak warning and format to PEP standards
107) Refactor the code so I'm not reloading the old db using the shelve module
    - Load the latest file from the Real Estate Data directory and turn the 'All Months ' and 'All Years' tabs into dictionaries
    - Load new data in to the main_dictionary and full_year dict then concatenate them to the 'All Months ' and 'All Years' tabs
    - Update the pandas2excel method to account for changes
71) Function that sends the data to an SQL Database
72) ***Look into aiohttp for async http requesting
- asyncio is pretty difficult to use
- there's something about the async setup that mixing up the split function for the cities with duplicate names
- the download pdf function isnt downloading anything
73) asynio Exceptions to my try-except blocks which use the module
75) Change the os.walk(base_path) to os.listdir(base_path) in read_logger (NOT NECESSARY)
The current code causes errors because its walking through all files and folders and trying to extract whats not there
https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory
79) Check back in a few days to determine campaign registration status on Twilio.com or email
80) Create decorator functions for these tasks:
    ***Use functool.wrapper to keep the metadata
 - Logger decorator function for:
    ***Change the logger level depending on the function running if possible
    ***May need to have "logger" as an arg to use in the function
    - CreateZip (properly place logger messages in function)
94) May need to alter the logic for the end_of_year variable with an if statement:
    if now = january, run zip
93) Create a decorator called quarterly_statistics
89) Make sure all the column datatypes are correct to calculate all stats
90) Make sure CreateZip runs as intended and the os.walk goes through all directories then set logger messages
91) Find a way to incorporate previous run date into run_main decorator
    Make sure the run_main function runs as intended
    It's not as intended right now, I need a way to check if the program has run already and if it has, check next month
99) Check all the try-except branches in the code to make sure they're being logged properly
    Use the help function on all of the Exception classes being used to make sure I'm capturing the most useful information
100) Should I be creating new Exception classes?
101) In case any errors are raised: I've changed the value calculation for percent_lpr_current
45) If the program is killed due to an exception, I want to be able to rerun the program X number of times
86) Create a function to upload the GIS Data and create cloropleth maps and timeseries maps:

    *** Create a time-series graph on the map of New Jersey for these categories as well
    - Download the CSV or GeoJSON (using Geopandas) from https://gisdata-njdep.opendata.arcgis.com/datasets/newjersey::municipal-boundaries-of-nj/explore?location=40.084926%2C-74.743150%2C8.00&showTable=true
    - Make sure the GeoJSON index matches the df index (rename the 'MUN' column to 'City') and join/merge the dfs

    def cloropleth_maps():
        import geopandas
        import plotly.express as px

        new_jersey = geopandas.read_file(filename, index = 'MUN')
        new_jersey.rename(columns = {'MUN': 'City'}, inplace = True)
        new_jersey[[column for column in new_jersey.columns]].sort_values(by=['City'])
        ***I have to sort the dfs by Qtr and year before plotting

        quarters = ['Q1', 'Q2', 'Q3', 'Q4']
        for sheet in list_of_excel_workbook_sheets:
            df = pd.read_excel('NJ 10k Real Estate', sheet)
            ***Create different dfs which are sorted dfs for Q1-Q4
            df_list = [df[[ for q in quarters
            fig = px.cloropleth()


    1) Create a function which creates line graphs and histograms for all categories for YTD for all cities of interest (sub x-axis will be by year)
        def target_areas_graphs(self):
            ***DF of Cites which have Top 10 Highest Median Closed Sales from all counties and filter for Median Sales Price < $750,000 (Decide on price later)

            by_qtr_stats = pd.read_excel('NJR Scrapper Data By Qtr Stats')
            years = temp_df['Year'].unique().to_list()
            temp_df = by_qtr_stats.copy()
            temp1_df = temp_df[['Year' == years[-1]]]
            counties  = temp_df['County'].unique().to_list()
            top10list = []

            for county in counties:
                temp2_df = temp1_df[['County' == county]]
                temp3_df = temp2_df.nlargest(10, 'Closed Sales(Median)')
                temp4_df = temp3_df[['Sales Price(Median)' < 750000]]
                top10list.append(temp4_df)

            target_cities_df = pd.concat(top10list)

    2) Create a function which creates histograms for all categories for YTD for all counties (sub x-axis will be by year)
        - Filter the new df by county
        def matplot_all_graphs(self):
    3) Use Seaborn to create pairplots on a state level then county level
        - Filter the new df by county and year
        import Seaborn





previous_dir = os.getcwd()
os.chdir('F:\\Python 2.0\\Projects\\Real Life Projects\\NJR Scrapper\\Saved Data')
with shelve.open('NJ Scrapper Data Dictionary') as saved_data_file:
    main_dictionary = saved_data_file['Main Dictionary']
    full_year = saved_data_file['Full Year']

os.chdir(previous_dir)

excelfile = obj.pandas2excel(main_dictionary, full_year)

njr10k_stats(excelfile)



Test String:
Key Metrics 2022 2023 Percent Change Thru 4-2022 Thru 4-2023 Percent Change
New Listings 25 13 - 48.0% 85 64 - 24.7%
Closed Sales 11 9 - 18.2% 46 37 - 19.6%
Days on Market Until Sale 36 42 + 16.7% 32 37 + 15.6%
Median Sales Price* $90,000 $101,000 + 12.2% $116,250 $95,000 - 18.3%
Percent of List Price Received* 107.8% 94.6% - 12.2% 99.7% 93.6% - 6.1%
Inventory of Homes for Sale 59 25 - 57.6% -- -- --
Months Supply of Inventory 4.8 2.0 - 58.3% -- -- --
Key Metrics 2022 2023 Percent Change Thru 4-2022 Thru 4-2023 Percent Change
New Listings 39 32 - 17.9% 134 131 - 2.2%
Closed Sales 19 34 + 78.9% 75 100 + 33.3%
Days on Market Until Sale 26 30 + 15.4% 39 46 + 17.9%
Median Sales Price* $70,000 $92,000 + 31.4% $72,334 $95,000 + 31.3%
Percent of List Price Received* 102.3% 99.8% - 2.4% 98.5% 97.6% - 0.9%
Inventory of Homes for Sale 86 61 - 29.1% -- -- --
Months Supply of Inventory 3.7 2.2 - 40.5% -- -- --
Key Metrics 2022 2023 Percent Change Thru 4-2022 Thru 4-2023 Percent Change
New Listings 0 0 -- 0 0 --
Closed Sales 0 0 -- 0 0 --
Days on Market Until Sale 0 0 -- 0 0 --
Median Sales Price* $0 $0 -- $0 $0 --
Percent of List Price Received* 0.0% 0.0% -- 0.0% 0.0% --
Inventory of Homes for Sale 0 0 -- -- -- --
Months Supply of Inventory 0.0 0.0 -- -- -- --
* Does not account for sale concessions and/or downpayment assistance.  |  Percent changes are calculated using rounded figures and can sometimes look extreme due to small sample size.Year to DateTownhouse-Condo April
Adult Community AprilYear to Date
Current as of May 20, 2023. All data from the multiple listing services in the state of New Jersey. Margin of error for reported statewide numbers is +/– 4% at a 95% confidence level. Report © 2023 ShowingTime.Local Market Update for April 2023
Provided by New Jersey REALTORS®
Camden City
Camden County
April Year to Date Single Family
$0$25,000$50,000$75,000$100,000$125,000$150,000$175,000
1-2010 1-2011 1-2012 1-2013 1-2014 1-2015 1-2016 1-2017 1-2018 1-2019 1-2020 1-2021 1-2022 1-2023Historical Median Sales Price by Property Type By Month
Single Family Townhouse-Condo Adult Community




8-4-23 Most recent updates (put in main file at home):
1) Put this in the for-loop in the main program to print better tables of the data

print(tabulate(main_dictionary['2022'], headers = 'keys', tablefmt = 'plain'))
print()
print(tabulate(main_dictionary['2023'], headers = 'keys', tablefmt = 'plain'))


4) New OrganizeFiles class (make sure to seperate .pdf and the logger files)



     | Traceback (most recent call last):
    |   File "F:/Python 2.0/Projects/Real Life Projects/NJRScrapper 8-17-23A.py", line 428, in download_pdf
    |     del city_list[city_list.index('/')]
    |                   ^^^^^^^^^^^^^^^^^^^^
    | ValueError: '/' is not in list

     | Traceback (most recent call last):
    |   File "F:/Python 2.0/Projects/Real Life Projects/NJRScrapper 8-17-23A.py", line 429, in download_pdf
    |     city_list.pop(city_list.index('/'))
    |                   ^^^^^^^^^^^^^^^^^^^^
    | ValueError: '/' is not in list

Traceback (most recent call last):
    |   File "F:/Python 2.0/Projects/Real Life Projects/NJRScrapper 8-17-23A.py", line 432, in download_pdf
    |     async with session_object.get(url3, params=params, stream=True) as reader, open(new_filename, 'wb') as writer:
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "F:\Python 2.0\pythonProject\venv\NJR Scrapper\Lib\site-packages\aiohttp\client.py", line 922, in get
    |     self._request(hdrs.METH_GET, url, allow_redirects=allow_redirects, **kwargs)
    | TypeError: ClientSession._request() got an unexpected keyword argument 'stream'

